"""
Find the 3D pose of a human hand using computer vision.

Using cv_bridge, take messages from the /image_raw topic and convert them
into OpenCV images for mediapipe to use to figure out where a user's hand
is located. Afterwards, figure out the 3D locations of the hand's joints
generated by mediapipe using the depth_image_proc package.

SUBSCRIBERS:
  + /camera/color/image_raw (Image) - Raw image data from the RealSense D435i
  camera.
  + /camera/aligned_depth_to_color/image_raw (Image) - Aligned depth image from
  the RealSense D435i camera.
PUBLISHERS:
  + /cv_image (Image) - Annotated image with the 3D location of the hand's
  pose.
  + /waypoint (PoseStamped) - The 3D location of the hand's pose.
  + /right_gesture (String) - The gesture that the right hand is making.

"""
import rclpy
from rclpy.node import Node
from rclpy.callback_groups import MutuallyExclusiveCallbackGroup

from geometry_msgs.msg import PoseStamped
from std_msgs.msg import String

import numpy as np

import pyautogui
import sys
import tty
import termios
from select import select


class HandCV(Node):
    def __init__(self):
        super().__init__("handcv")

        # create callback groups
        self.timer_callback_group = MutuallyExclusiveCallbackGroup()
        self.waypoint_callback_group = MutuallyExclusiveCallbackGroup()

        # create timer
        self.timer = self.create_timer(
            1/30, self.timer_callback, callback_group=self.timer_callback_group)

        self.waypoint_pub = self.create_publisher(
                PoseStamped, 'waypoint', 10)

        self.right_gesture_pub = self.create_publisher(
                String, 'right_gesture', 10)

        # intialize other variables
        self.waypoint = PoseStamped() 
        self.waypoint.pose.orientation.x = 1.0
        self.waypoint.pose.orientation.w = 0.0
        self.centroid = np.array([0.0, 0.0, 0.0])

        # create timer
        self.timer = self.create_timer(0.01, self.timer_callback)

        # keyboard hot keys
        self.get_logger().info("Press the letter 'b' to begin tracking mouse position.\n")
        self.get_logger().info("Press the letter 's' to stop tracking mouse position.\n")
        self.get_logger().info("Press the letter 'o' to open gripper.\n")
        self.get_logger().info("Press the letter 'c' to close gripper.\n")
        self.get_logger().info("Press the letter 'x' to terminal the node.\n")
        self.settings = termios.tcgetattr(sys.stdin)
        self.timeout = 0.01

        self.listening = True
        self.tracking = False
        self.command_mode = 'None'

    def getKey(self):

        try:
            tty.setraw(sys.stdin.fileno())
            # sys.stdin.read() returns a string on Linux
            rlist, _, _ = select([sys.stdin], [], [], self.timeout)
            if rlist:
                self.key = sys.stdin.read(1)
            else:
                self.key = None
        except Exception as e:
            self.get_logger().info(f'ERROR: {e}')
        
    def check_keys(self):

        if self.key == 'b':
            self.get_logger().info(f'Tracking mouse position now.\r\n')
            self.command_mode = 'Thumbs_Up'
            self.tracking = True
        elif self.key == 's':
            self.get_logger().info(f'Stopping tracking mouse position now.\r\n')
            self.command_mode = 'Thumbs_Down'
            self.tracking = False
        elif self.key == 'o':
            self.get_logger().info(f'Opening gripper now.\r\n')
            self.command_mode = 'Open_Palm' 
        elif self.key == 'c':
            self.get_logger().info(f'Closing gripper now.\r\n')
            self.command_mode = 'Closed_Fist'
        elif self.key == 'x':
            self.get_logger().info(f'Terminating node now.\r\n')
            self.listening = False
            termios.tcsetattr(sys.stdin, termios.TCSADRAIN, self.settings)
            raise 'Node Terminated.'

    def timer_callback(self):
        """Publish the annotated image and the waypoint for the arm"""
        
        # listening for keys
        if self.listening:

            self.getKey()
            self.check_keys()

        if self.tracking:
            self.centroid[0], self.centroid[1] = pyautogui.position()

        # publish command mode
        self.right_gesture_pub.publish(String(data=self.command_mode))
        
        # publish the waypoint
        self.waypoint.header.stamp = self.get_clock().now().to_msg()
        self.waypoint.pose.position.x = self.centroid[0]
        self.waypoint.pose.position.y = self.centroid[1]
        self.waypoint.pose.position.z = self.centroid[2]
        self.waypoint_pub.publish(self.waypoint)


def main(args=None):
    rclpy.init(args=args)

    handcv = HandCV()

    rclpy.spin(handcv)


if __name__ == '__main__':
    main()
